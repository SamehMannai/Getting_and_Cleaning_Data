fixed <- read.fwf(url, widths, header = FALSE, skip = 4)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
lines <- readLines(url, "n=10")
data <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",
skip = 4,
widths = c(12, 7,4, 9,4, 9,4, 9,4))
sum(data[, 4])
data <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",
skip = 4,
widths = c(12, 7,4, 9,4, 9,4, 9,4))
data <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", skip = 4, widths = c(12, 7,4, 9,4, 9,4, 9,4))
sum(data[, 4])
data <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", skip = 4, widths = c(12, 7,4, 9,4, 9,4, 9,4))
setInternet2(TRUE) works
setInternet2(TRUE)
setInternet2(TRUE)
data <- read.fwf(file = "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", skip = 4, widths = c(12, 7,4, 9,4, 9,4, 9,4))
sum(data[, 4])
data <- read.fwf(file = "http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", skip = 4, widths = c(12, 7,4, 9,4, 9,4, 9,4))
sum(data[, 4])
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
widths <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
fixed <- read.fwf(con, widths, header = FALSE, skip = 4)
sum(fixed$V8)
con <- url("http://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
lines <- readLines(con, n=10)
lines
widths <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
fixed <- read.fwf(con, widths, header = FALSE, skip = 4)
head(fixed)
library(dplyr)
install.packages("dplyr")
options(width = 105)
chicago <- read RDS("chicago.rds")
options(width = 105)
chicago <- readRDS("chicago.rds")
chicago
?chicago
library(dplyr)
library(dplyr)
options(width = 105)
chicago <- readRDS("chicago.rds")
setwd("/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Getting_and_Cleaning_Data/Week3/")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url=fileUrl,destfile="idaho_housing.csv",mode="w",method="curl")
idaho_housing <- read.csv("idaho_housing.csv")
head(idaho_housing)
str(idaho_housing)
names(idaho_housing)
agricultureLogical <- length(idaho_housing$AGS[!is.na(idaho_housing$AGS) & idaho_housing$AGS==6])
agricultureLogical
which(agricultureLogical)
data <- read.csv("idaho_housing.csv")
head(data$AGS[!is.na(data$AGS) & idata$AGS==6 & data$ACR==6])
data <- read.csv("idaho_housing.csv")
head(data$AGS[!is.na(data$AGS) & idata$AGS==6 & data$ACR==6])
head(data[idata$AGS==6 & data$ACR==6])
head(data[data$AGS==6 & data$ACR==6])
head(data$AGS==6 & data$ACR==6)
head(data$AGS==6 & data$ACR==6, n=3)
head(data$AGS==6 & data$ACR==3, n=3)
head(data$AGS[!is.na(data$AGS) & idata$AGS==6 & data$ACR==6])
head(data$AGS[!is.na(data$AGS) & idata$AGS==6 & data$ACR==3])
head(data$AGS[!is.na(data$AGS) & data$AGS==6 & data$ACR==3])
head(data$AGS[!is.na(data$AGS) & data$AGS >=6 & data$ACR>=3])
library(dplyr)
head(data[which(data$ACR >=3 & data$AGS >=6),],n=3)
head(data[which(data$ACR >=3 & data$AGS >=6),],n=3)
data[which(ata$AGS==6 & data$ACR==3) ]
data[which(data$AGS==6 & data$ACR==3) ]
data <- read.csv("idaho_housing.csv")
data[which(data$AGS==6 & data$ACR==3), ]
head(data[which(data$AGS==6 & data$ACR==3), ],n=3)
head(data[,which(data$AGS==6 & data$ACR==3) ],n=3)
head(data[which(data$AGS==6 & data$ACR==3), ],n=3)
agricultureLogical <- data$AGS==6 & data$ACR==3
which(agricultureLogical)
agricultureLogical <- c(data$AGS==6 & data$ACR==3)
which(agricultureLogical)
agricultureLogical <- c("data$AGS==6 & data$ACR==3")
which(agricultureLogical)
head(data[!is.na(data$AGS) & data$AGS==6 & data$ACR==6,])
head(data[data(!is.na(data$AGS) & data$AGS==6 & data$ACR==6),])
head(data[ data$AGS==6 & data$ACR==6,])
head(data[ data$AGS==6 & data$ACR==3,])
data[data$AGS==6 & data$ACR==3,]
setwd("/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Getting_and_Cleaning_Data/Week3/")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url=fileUrl,destfile="idaho_housing.csv",mode="w",method="curl")
data <- read.csv("idaho_housing.csv")
head(data[which(data$AGS==6 & data$ACR==3), ],n=3)
data[data$AGS==6 & data$ACR==3,]
head(data[data$AGS >=6 & data$ACR >=3,])
data[(data$AGS >=6 & data$ACR >=3),]
head(which(agricultureLogical),3)
agricultureLogical <- data$AGS==6 & data$ACR==3
head(which(agricultureLogical),3)
URL = 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
image = '/Users/zhusiqi/Desktop/coursera/R_jhu/geting_and_cleaning_data/week3/q2.jpg'
download.file(URL, image, mode = 'wb', method = 'curl')
data_image = readJPEG(image, native = TRUE)
quantile(data_image, probs = c(0.3, 0.8))
install.packages("JPEG")
install.packages("jpeg")
URL = 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
image = '/Users/zhusiqi/Desktop/coursera/R_jhu/geting_and_cleaning_data/week3/q2.jpg'
download.file(URL, image, mode = 'wb', method = 'curl')
data_image = readJPEG(image, native = TRUE)
quantile(data_image, probs = c(0.3, 0.8))
?readJPEG
?readJPEG()
install.packages("jpeg")
data_image = readJPEG(image, native = TRUE)
library(jpeg)
data_image = readJPEG(image, native = TRUE)
mage = '/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Geting_and_Cleaning_Data/Week3/jeff.jpg'
download.file(URL, image, mode = 'wb', method = 'curl')
image = '/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Geting_and_Cleaning_Data/Week3/jeff.jpg'
download.file(URL, image, mode = 'wb', method = 'curl')
URL = 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
image = '/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Geting_and_Cleaning_Data/Week3/jeff.jpg'
download.file(URL, image, mode = 'wb', method = 'curl')
URL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
image = "/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Geting_and_Cleaning_Data/Week3/jeff.jpg"
download.file(URL, image, mode = "w", method = "curl")
data_image = readJPEG(image, native = TRUE)
quantile(data_image, probs = c(0.3, 0.8))
setwd("/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Getting_and_Cleaning_Data/Week3/")
URL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(URL, destfile="jeff.jpg", mode = "w", method = "curl")
data_image = readJPEG(destfile, native = TRUE)
data_image = readJPEG("jeff.jpg", native = TRUE)
quantile(data_image, probs = c(0.3, 0.8))
if(!file.exists("./data")){dir.create("./data")}
fileUrl1<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
fileUrl2<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1,destfile="./data/getdataFGDP.csv",method="curl")
download.file(fileUrl2,destfile="./data/getdataCountry.csv",method="curl")
data1<-read.csv("./data/getdataFGDP.csv", header=F, skip=5, nrows=190)
data2<-read.csv("./data/getdataCountry.csv")
library(dplyr)
names(data1)
names(data2)
head(data1,2)
head(data2,2)
datamerged<-(data1,data1,by.x="V1",by.y="CountryCode")
datamerged<-(data1,data2,by.x="V1",by.y="CountryCode")
datamerged<-merge(data1,data2,by.x="V1",by.y="CountryCode")
datamergedarr<-arrange(datamerged,desc(V2))
ans1<-nrow(datamerged)
ans1
ans2<-datamergedarr$V4[13]
ans2
MergedData<-merge(data1,data2,by.x="V1",by.y="CountryCode")
ArrangedData<-arrange(MergedData,desc(V2))
ans1<-nrow(MergedData)
ans1
ans2<-ArrangedData$V4[13]
ans2
Selected_data_1<-filter(ArrangedData,Income.Group=="High income: OECD")
Selected_data_2<-filter(ArrangedData,Income.Group=="High income: nonOECD")
answer1<-mean(Selected_data_1$V2)
answer1
answer2<-mean(Selected_data_2$V2)
answer2
tapply(MergedData$Rank, MergedData$`Income Group`, mean)
tapply(MergedData$Rank, MergedData$"Income Group", mean)
factor<-quantile(ArrangedData$V2,c(0.2,0.4,0.6,0.8,1))
q1 <- ArrangedData$V2 <= 38
xtabs(q1 ~ ArrangedData$Income.Group)
factor
q1
q1 ~ ArrangedData$Income.Group
tabs(q1 ~ ArrangedData$Income.Group)
xtabs(q1 ~ ArrangedData$Income.Group)
q1 <- ArrangedData$V2 <= 38
xtabs(q1 ~ ArrangedData$Income.Group)
rrangedData1<-arrange(MergedData,desc(V2))
q1 <- rrangedData1$V2 <= 38
xtabs(q1 ~ rrangedData1$Income.Group)
table(ArrangedData$V2, ArrangedData$`Income Group`)
table(ArrangedData$V2, ArrangedData$`Income Group`)
table(ArrangedData$V2, ArrangedData$Income.Group)
ArrangedData$V2 <- cut2(ArrangedData$Income.Group, g=5)
ArrangedData$V2 <- cut(ArrangedData$Income.Group, g=5)
factor<-quantile(ArrangedData$V2,probs=c(0.2,0.4,0.6,0.8,1))
factor<-quantile(ArrangedData$V2,na.rm=TRUE)
factor
factor<-quantile(ArrangedData$V2,probs=c(0.2,0.4,0.6,0.8,1))
factor
MergedData<-merge(data1,data2,by.x="V1",by.y="CountryCode")
ArrangedData<-arrange(MergedData,desc(V2))
factor<-quantile(ArrangedData$V2,c(0.2,0.4,0.6,0.8,1))
q1 <- ArrangedData$V2 <= 38
xtabs(q1 ~ ArrangedData$Income.Group)
MergedData<-merge(data1,data2,by.x="V1",by.y="CountryCode")
ArrangedData<-arrange(MergedData,desc(V2))
factor<-quantile(ArrangedData$V2,c(0.25,0.5,0.75,1))
q1 <- ArrangedData$V2 <= 38
xtabs(q1 ~ ArrangedData$Income.Group)
names(data2)
q1 <- ArrangedData$V2 <= 38
xtabs(q1 ~ ArrangedData$Income.Group)
xtabs( Freq ~ ArrangedData$V2 + ArrangedData$Income.Group, q1)
xtabs( Freq ~ ArrangedData$V2 + ArrangedData$Income.Group, data=q1)
xtabs( Freq ~ V2 + Income.Group, data=q1)
setwd("/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Getting_and_Cleaning_Data/Week3/")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url=fileUrl,destfile="idaho_housing.csv",mode="w",method="curl")
data <- read.csv("idaho_housing.csv")
setwd("/home/smannai/Dropbox/CV-Anglais/Industrie/coursera/Getting_and_Cleaning_Data/Week4/")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url=fileUrl,destfile="idaho_housing.csv",mode="w",method="curl")
data <- read.csv("idaho_housing.csv")
head(data)
splitNames = strsplit(names(data),"\\.")
splitNames[[123]]
splitNames = strsplit(names(data),"\\.")
splitNames[[123]]
splitNames[123]
data <- read.csv("idaho_housing.csv")
splitNames = strsplit(names(data),"\\.")
splitNames[123]
data <- read.csv("idaho_housing.csv")
splitNames = strsplit(names(data),"wgtp")
splitNames[123]
splitNames
head(data)
if(!file.exists("./data")){dir.create("./data")}
fileUrl1<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl1,destfile="./data/getdataFGDP.csv",method="curl")
data1<-read.csv("./data/getdataFGDP.csv", header=F, skip=5, nrows=190)
names(data1)
head(data1,2)
cleandata<-sub(",","",names(data1),)
mean(cleandata, na.rm =TRUE)
cleandata<-sub(",","",names(data1))
mean(cleandata, na.rm =TRUE)
cleandata<-sub(",","",data1[,5])
cleandata<-(as.numeric(cleandata))
mean(cleandata, na.rm =TRUE)
cleandata<-gsub(",","",data1[,5])
cleandata<-(as.numeric(cleandata))
mean(cleandata, na.rm =TRUE)
cleandata<-gsub(",","",data1[,4])
cleandata<-(as.numeric(cleandata))
mean(cleandata, na.rm =TRUE)
grep("^United",data1[,4])
grep("^United",data1[,4]),3
grep("^United",data1[,4]),4
grep("^United",data1[,4])
countryNames <-data1[1,4]
grep("^United",countryNames), 3
countryNames <-data1[,4]
grep("^United",countryNames), 3
data1<-read.csv("./data/getdataFGDP.csv", header=F, skip=5, nrows=190)
countryNames <-data1[,4]
grep("^United",countryNames), 3
countryNames <-data1$X.3
grep("^United",countryNames), 3
june <- grepl("june", tolower(MergedData$Special.Notes))
length(june)
june <- grepl("Fiscal year end: June", tolower(MergedData$Special.Notes))
length(june)
june <- grepl("Fiscal year end: June", MergedData$Special.Notes)
length(june)
FiscalYearEnd <- grepl("fiscal year end", tolower(MergedData$Special.Notes))
June <- grepl("june", tolower(MergedData$Special.Notes))
table(FiscalYearEnd, June)
length(June)
library(quantmod)
install.packages(quantmod)
install.packages("quantmod)
install.packages("quantmod")
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
addmargins(table(year(sampleTimes), weekdays(sampleTimes)))
length(grep("^2012",sampleTimes))
library(lubridate)
installed.packages("lubridate")
install.packages("lubridate")
addmargins(table(year(sampleTimes), weekdays(sampleTimes)))
sampleTimes[grep("^2012",sampleTimes)]
sum(weekdays(as.Date(sampleTimes[grep("^2012",sampleTimes)]))=="Monday")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
length(grep("^2012",sampleTimes))
library(lubridate)
sampleTimes[grep("^2012",sampleTimes)]
sum(weekdays(as.Date(sampleTimes[grep("^2012",sampleTimes)]))=="Monday")
2
3
4
year2012 <- grepl('2012-*', sampleTimes)
sampleTimes2012 <- subset(sampleTimes, year2012)
day <- format(sampleTimes2012, '%A')
table(year2012)
table(day)
source('~/.active-rstudio-document')
installed.packages("data.table")
install.packages("data.table")
source('~/.active-rstudio-document')
install.packages("reshape2")
source('~/.active-rstudio-document')
unzip(zipfile="./Project/Dataset.zip",exdir="./Project")
file.remove( "./Project/Dataset.zip" )
pathIn <- file.path("./Project", "UCI HAR Dataset")
list.files(pathIn, recursive = TRUE)
list.files("./Project", recursive = TRUE)
list.files("./Project", "UCI HAR Dataset", recursive = TRUE)
pwd<- file.path("./Project", "UCI HAR Dataset")
list.files(pwd, recursive = TRUE)
x_train <- read.table("./Project/UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./Project/UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./Project/UCI HAR Dataset/train/subject_train.txt")
# Reading testing tables:
x_test <- read.table("./Project/UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./Project/UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./Project/UCI HAR Dataset/test/subject_test.txt")
# Reading feature vector:
features <- read.table("./Project/UCI HAR Dataset/features.txt")
# Reading activity labels:
activityLabels = read.table("./Project/UCI HAR Dataset/activity_labels.txt")
colnames(x_train) <- features[,2]
colnames(y_train) <-"activityId"
colnames(subject_train) <- "subjectId"
colnames(x_test) <- features[,2]
colnames(y_test) <- "activityId"
colnames(subject_test) <- "subjectId"
colnames(activityLabels) <- c('activityId','activityType')
data_train <- cbind(y_train, subject_train, x_train)
data_test <- cbind(y_test, subject_test, x_test)
all_data <- rbind(data_train, data_test)
## 2.Extracts only the measurements on the mean and standard deviation for each measurement.
# Reading column names from all_data:
colNames <- colnames(all_data)
#  Create a logical vector for defining ID, mean and standard deviation:
mean_and_std <- (grepl("activityId" , colNames) |
grepl("subjectId" , colNames) |
grepl("mean.." , colNames) |
grepl("std.." , colNames) )
setForMeanAndStd <- all_Data[ , mean_and_std == TRUE]
setForMeanAndStd <- all_data[ , mean_and_std == TRUE]
head(all_data)
head(setForMeanAndStd)
source('~/.active-rstudio-document')
MeanAndStdAndActivityNames_data
setWithActivityNames <- merge(MeanAndStdAndActivityNames_data , activityLabels,
by='activityId',
all.x=TRUE)
setWithActivityNames
head(MeanAndStdAndActivityNames_data)
colNames(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("^f", "frequency", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Gyro", "Gyroscope", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Mag", "Magnitude", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("BodyBody", "Body", colNames(MeanAndStdAndActivityNames_data))
colNames <- colnames(MeanAndStdAndActivityNames_data);
colNames(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("^f", "frequency", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Gyro", "Gyroscope", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Mag", "Magnitude", colNames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("BodyBody", "Body", colNames(MeanAndStdAndActivityNames_data))
colNames <- colnames(MeanAndStdAndActivityNames_data);
colNames(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", colNames(MeanAndStdAndActivityNames_data))
colnames <- colnames(MeanAndStdAndActivityNames_data);
colnames <- make.names(colnames, unique=TRUE)
colNames<-gsub("^t", "time", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("^f", "frequency", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Acc", "Accelerometer", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Gyro", "Gyroscope", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Mag", "Magnitude", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("BodyBody", "Body", colnames(MeanAndStdAndActivityNames_data))µ
colNames<-gsub("^f", "frequency", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Acc", "Accelerometer", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Gyro", "Gyroscope", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Mag", "Magnitude", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("BodyBody", "Body", colnames(MeanAndStdAndActivityNames_data))
colnames(MeanAndStdAndActivityNames_data) <- colNames;
str(MeanAndStdAndActivityNames_data)
colnames <- colnames(MeanAndStdAndActivityNames_data);
colnames <- make.names(colnames, unique=TRUE)
colNames<-gsub("^t", "time", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("^f", "frequency", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Acc", "Accelerometer", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Gyro", "Gyroscope", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Mag", "Magnitude", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("BodyBody", "Body", colnames(MeanAndStdAndActivityNames_data))
# Reassigning the new descriptive column names to the finalData set
colnames(MeanAndStdAndActivityNames_data) <- colNames
str(MeanAndStdAndActivityNames_data)
MeanAndStd_data <- all_data[ , logic_mean_std == TRUE]
## 3. Uses descriptive activity names to name the activities in the data set
# Merge the MeanAndStd_data set with the acitivityType table to include the names of the descriptive activity
MeanAndStdAndActivityNames_data <- merge(MeanAndStd_data, activityLabels, by='activityId', all.x=TRUE)
##4.Appropriately labels the data set with descriptive variable names.
# Cleaning up the variable names
colnames <- colnames(MeanAndStdAndActivityNames_data);
colnames <- make.names(colnames, unique=TRUE)
colNames<-gsub("^t", "time", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("^f", "frequency", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Acc", "Accelerometer", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Gyro", "Gyroscope", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("Mag", "Magnitude", colnames(MeanAndStdAndActivityNames_data))
colNames<-gsub("BodyBody", "Body", colnames(MeanAndStdAndActivityNames_data))
# Reassigning the new descriptive column names to the finalData set
colnames(MeanAndStdAndActivityNames_data) <- colNames
## 5.From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
str(MeanAndStdAndActivityNames_data)
colnames <- colnames(MeanAndStdAndActivityNames_data);
colnames <- make.names(colnames, unique=TRUE)
colnames<-gsub("^t", "time", colnames(MeanAndStdAndActivityNames_data))
colnames<-gsub("^f", "frequency", colnames(MeanAndStdAndActivityNames_data))
str(MeanAndStdAndActivityNames_data)
colnames(MeanAndStdAndActivityNames_data) <- colnames
str(MeanAndStdAndActivityNames_data)
names<-gsub("^t", "time", names(MeanAndStdAndActivityNames_data))
names<-gsub("^f", "frequency", names(MeanAndStdAndActivityNames_data))
str(MeanAndStdAndActivityNames_data)
names(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", names(MeanAndStdAndActivityNames_data))
str(MeanAndStdAndActivityNames_data)
colNames(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", colnames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Gyro", "Gyroscope", colnames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("Mag", "Magnitude", colnames(MeanAndStdAndActivityNames_data))
colNames(MeanAndStdAndActivityNames_data)<-gsub("BodyBody", "Body", colnames(MeanAndStdAndActivityNames_data))
colnames(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", colnames(MeanAndStdAndActivityNames_data))
str(MeanAndStdAndActivityNames_data)
names(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("^f", "frequency", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Gyro", "Gyroscope", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Mag", "Magnitude", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("BodyBody", "Body", names(MeanAndStdAndActivityNames_data))
# Reassigning the new descriptive column names to the finalData set
names(MeanAndStdAndActivityNames_data) <- names
str(MeanAndStdAndActivityNames_data)
str(MeanAndStdAndActivityNames_data)
names(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("^f", "frequency", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Gyro", "Gyroscope", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Mag", "Magnitude", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("BodyBody", "Body", names(MeanAndStdAndActivityNames_data))
str(MeanAndStdAndActivityNames_data)
str(MeanAndStdAndActivityNames_data)
names(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("^f", "frequency", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Gyro", "Gyroscope", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Mag", "Magnitude", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("BodyBody", "Body", names(MeanAndStdAndActivityNames_data))
data_train <- cbind(y_train, subject_train, x_train)
data_test <- cbind(y_test, subject_test, x_test)
all_data <- rbind(data_train, data_test)
## 2.Extracts only the measurements on the mean and standard deviation for each measurement.
# Reading column names from all_data:
colNames <- colnames(all_data)
#  Create a logical vector for defining ID, mean and standard deviation:
logic_mean_std <- (grepl("activityId" , colNames) |
grepl("subjectId" , colNames) |
grepl("mean.." , colNames) |
grepl("std.." , colNames) )
# Subset all_data table based on  logic_mean_std to keep only the desired columns in MeanAndStd_data
MeanAndStd_data <- all_data[ , logic_mean_std == TRUE]
## 3. Uses descriptive activity names to name the activities in the data set
# Merge the MeanAndStd_data set with the acitivityType table to include the names of the descriptive activity
MeanAndStdAndActivityNames_data <- merge(MeanAndStd_data, activityLabels, by='activityId', all.x=TRUE)
##4.Appropriately labels the data set with descriptive variable names.
names(MeanAndStdAndActivityNames_data)<-gsub("^t", "time", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("^f", "frequency", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Acc", "Accelerometer", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Gyro", "Gyroscope", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("Mag", "Magnitude", names(MeanAndStdAndActivityNames_data))
names(MeanAndStdAndActivityNames_data)<-gsub("BodyBody", "Body", names(MeanAndStdAndActivityNames_data))
str(MeanAndStdAndActivityNames_data)
TidyDataSet <- aggregate(. ~subjectId + activityId, MeanAndStdAndActivityNames_data, mean)
TidyDataSet <- TidyDataSet[order(TidyDataSet$subjectId, TidyDataSet$activityId),]
# Writing second tidy data set in txt file
write.table(TidyDataSet, "TidyDataSet.txt", row.name=FALSE)
library(knitr)
knit2html("codebook.Rmd");
install.packages("knitr")
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd");
library(knitr)
knit2html("codebook.Rmd")
knit2html("codebook.Rmd")
knit2html("codebook.Rmd")
knit2html("codebook.Rmd")
knit2html("codebook.Rmd")
knit2html("codebook.Rmd")
codebook(MeanAndStdAndActivityNames_data)
codebook(tiny_data.txt)
codebook("tiny_data.txt)
codebook("tiny_data.txt")
